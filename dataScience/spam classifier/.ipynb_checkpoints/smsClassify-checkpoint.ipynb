{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview Practice- Machine Learning\n",
    "Topic: SMS Spam Classifier <br>\n",
    "Written by: Chieh-An Liang <br>\n",
    "Date: 16/12/2018 <br>\n",
    "version: 1.2 <br>\n",
    "\n",
    "Updates: \n",
    "1. Format in report style\n",
    "2. Explore data in detail- how to deal with imbalance data\n",
    "3. Re-evaulate performance criteria\n",
    "4. Plot learning curve to track overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Step 1: Analyze data </b>\n",
    "    \n",
    "First step is to load the data from the CSV file into a pandas frame, which we can better analyze and process data.\n",
    "As we can see from the data distribution that it is uneven- 87% ham v.s. 13% spam. Normally we need to resample our data to prevent prediction incline towards ham, but since we use Naive bayes, the uneven data distribution has been accounted for (prior).\n",
    "\n",
    "We should also look at the overall word frequency. <br>\n",
    "The top 10 words for ham by frequency: <br>\n",
    "The top 10 words for spam by frequency: <br>\n",
    "For example, if a given text contains \"FREE\" , it is more likely to be a spam. \n",
    "\n",
    "Also from the data, there is a minuscule amount of words in column 3,4,5, but for the simplicity, we drop it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam % =  13.406317300789663\n",
      "Spam % =  86.59368269921033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "csv = pd.read_csv(\"spam.csv\",encoding='latin-1', header=0, names=['label', 'sms1','sms2','sms3', 'sms4']).drop(['sms2','sms3','sms4'], axis=1)\n",
    "\n",
    "ham = len(csv[csv['label'] == 'ham'])\n",
    "spam = len(csv[csv['label'] == 'spam'])\n",
    "\n",
    "spam_percent= spam / len(csv) *100\n",
    "ham_percent = ham / len(csv) *100\n",
    "\n",
    "print(\"Spam % = \", spam_percent)\n",
    "print(\"Spam % = \", ham_percent)\n",
    "\n",
    "\n",
    "csv.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<b>Step 2: Preprocessing/ Feature extraction</b>\n",
    "\n",
    "\n",
    "\n",
    "Because we use Naive Bayes (multinomial) bag of words model, we need to tokenize the text into a vector matrix. Feature corresponds to word in text.\n",
    "\n",
    "A basic preprocessing step is to remove meaningless symbol such as !@#$^&*(){}[]. Regular expression split the word/ remove the delimiter by identifying the non-alphanumeric characters.\n",
    "\n",
    "Then we use TFidf as we are interested in the token frequency. TFidf considers both the effect of the local (term frequency) and global (document frequency) and is traditionally used to calculate the relevance of a query to a document. Similarly, tfidf is used to measure the relevance of the text to a corresponding label/ classification. \n",
    "We use the default TFidf transformer setting: norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False.\n",
    "\n",
    "Finally, we split the corpus into 2 datasets: training and testing. Since data is imblanced, we need to set Stratify to true to make sure even distribution of labels into each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "def tokenization(spam):\n",
    "    tokens={}\n",
    "    spam= spam.strip()\n",
    "    for token in re.split(r'[^A-Za-z0-9]+', spam):\n",
    "        token=token.lower()\n",
    "        if token not in tokens:\n",
    "            tokens[token]= 1\n",
    "        else:\n",
    "            tokens[token]+=1\n",
    "    return tokens\n",
    "\n",
    "word_matrix=[]\n",
    "for i in csv['sms1']:\n",
    "    word_matrix.append(tokenization(i))\n",
    "\n",
    "\n",
    "v = DictVectorizer()\n",
    "xcount= v.fit_transform(word_matrix)\n",
    "\n",
    "tv = TfidfTransformer()\n",
    "X_train_tfidf = tv.fit_transform(xcount)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, csv['label'], test_size=0.2, random_state=42, stratify=csv['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "<b>Step 3: Model Training</b>\n",
    "    \n",
    "We use multinomial naive bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "Mnb = MultinomialNB()\n",
    "Mnb.fit(X_train, y_train)\n",
    "\n",
    "Bnb = BernoulliNB()\n",
    "Bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<b> Step 4: Model Evaluation </b>\n",
    "We care about both accuracy and precision, therefore we use weighted F1 score. Assume equal importance.\n",
    "\n",
    "F1 score formula= 2 * Precision * Recall/ (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "y_score= Mnb.score(X_test, y_test)\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "\n",
    "\n",
    "#print('multinomial accuracy: ', multinomial_accuracy)\n",
    "#print('bernoulli accuracy: ', bernoulli_accuracy)\n",
    "\n",
    "\n",
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Testing score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.1, random_state=42)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "plot_learning_curve(GaussianNB(), \"Learning Curves\", X_train.toarray(), y_train, ylim=(0.8, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomial prediction for ham:  ['ham']\n",
      "multinomial prediction for spam:  ['spam']\n",
      "bernoulli prediction for ham:  ['ham']\n",
      "bernoulli prediction for spam:  ['ham']\n"
     ]
    }
   ],
   "source": [
    "#6 Prediction\n",
    "\n",
    "ham_feed= \"have a party tonight to celebrate winning the lottery, don't be late! Max\"\n",
    "spam_feed= \"congratulation! you won the US Mega Pot, claim it before august 21 by replying to 042346742\"\n",
    "\n",
    "\n",
    "predict_ham=v.transform([tokenization(ham_feed)])  \n",
    "predict_spam= v.transform([tokenization(spam_feed)])  \n",
    "\n",
    "\n",
    "print('multinomial prediction for ham: ', Mnb.predict(predict_ham))\n",
    "print('multinomial prediction for spam: ',Mnb.predict(predict_spam))\n",
    "\n",
    "print('bernoulli prediction for ham: ',Bnb.predict(predict_ham))\n",
    "print('bernoulli prediction for spam: ',Bnb.predict(predict_spam))\n",
    "\n",
    "# multinomial predicts both case correct, bernoulli only 1, multinomial more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
